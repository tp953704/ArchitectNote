{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of required dependencies ðŸ’¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (0.3.35)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain) (2.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-ollama in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (0.2.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-ollama) (0.3.35)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-ollama) (0.4.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.10.6)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in /Users/karthik/tryout/LangchainTraining/myenv312/lib/python3.12/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-ollama\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intracting with LLM\n",
    "\n",
    "<img src=\"./Images/LocalLLM.png\" width=\"800\" height=\"400\" style=\"display: block; margin: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm doing well, thank you for asking. As an AI, I don't have feelings, but I'm here and ready to help you with any questions or tasks you might have. How can I assist you today?\" additional_kwargs={} response_metadata={'model': 'qwen2.5:latest', 'created_at': '2025-02-17T04:21:17.209651Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1302512958, 'load_duration': 30077625, 'prompt_eval_count': 37, 'prompt_eval_duration': 288000000, 'eval_count': 48, 'eval_duration': 982000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-063c901c-b1a7-4938-b370-424324ed9989-0' usage_metadata={'input_tokens': 37, 'output_tokens': 48, 'total_tokens': 85}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model = \"qwen2.5:latest\",\n",
    "    temperature=0.5,\n",
    "    max_tokens = 250\n",
    ")\n",
    " \n",
    "response = llm.invoke(\"Hello, how are you doing today?\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ENV file will connect LangSmith\n",
    "\n",
    "<img src=\"./Images/LocalLLMWithLangSmith.png\" width=\"800\" height=\"400\" style=\"display: block; margin: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load = load_dotenv('./../.env', override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt & Chat Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the advantage of running the LLM in local machine'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"What is the advantage of running the LLM in {env}\");\n",
    "\n",
    "prompt = prompt_template.invoke({\"env\": \"local machine\"})\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "content = llm.invoke(prompt).content\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Large Language Models (LLMs) on your local machine can offer several advantages, depending on your specific use case and requirements. Here are some key benefits:\n",
      "\n",
      "1. **Control and Privacy**: Running an LLM locally gives you complete control over the data it processes. This is particularly important if you're working with sensitive or confidential information.\n",
      "\n",
      "2. **Latency Reduction**: For applications where real-time responses are crucial, running the model on your local machine can significantly reduce latency compared to cloud-based solutions. This is especially beneficial for interactive applications like chatbots or virtual assistants.\n",
      "\n",
      "3. **Offline Use**: With a locally installed LLM, you can use it even when there's no internet connection, which can be advantageous in scenarios where connectivity might be an issue.\n",
      "\n",
      "4. **Customization and Modification**: You have the flexibility to customize and modify the model according to your specific needs. This could include adding custom data, fine-tuning the model for better performance on a particular task, or integrating it with other local applications without relying on external services.\n",
      "\n",
      "5. **Cost Savings**: While cloud-based models can be cost-effective for large-scale deployments due to shared resources and pay-as-you-go pricing, running an LLM locally eliminates ongoing costs associated with cloud usage.\n",
      "\n",
      "6. **Scalability Control**: You have more control over how the model scales. For instance, you can adjust the hardware configuration of your local machine to better suit the computational demands of the model without being constrained by cloud service limits.\n",
      "\n",
      "7. **Debugging and Testing**: Debugging and testing a locally running LLM can be easier since you don't need to rely on external dependencies or services. This can speed up development cycles and improve overall productivity.\n",
      "\n",
      "However, it's important to note that running an LLM on your local machine also comes with certain challenges, such as the need for powerful hardware (like GPUs), increased storage requirements due to model size, and potential complexity in deployment and maintenance compared to cloud-based solutions.\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AI models on a local machine offers several advantages, including:\n",
      "\n",
      "1. **Data Privacy and Security**: Processing data locally ensures that sensitive information does not leave your network or device, which can be crucial for compliance with regulations such as GDPR or HIPAA.\n",
      "\n",
      "2. **Reduced Latency**: Local processing reduces the time it takes to transfer data over a network to remote servers, leading to faster inference times. This is particularly important in real-time applications like autonomous vehicles or interactive chatbots.\n",
      "\n",
      "3. **Offline Capabilities**: Models can be run without an internet connection once they have been trained and saved locally, which can be beneficial for scenarios where constant connectivity is not available.\n",
      "\n",
      "4. **Cost Efficiency**: Running models on local hardware can reduce costs associated with cloud services, especially if the model does not require high computational resources that are typically more expensive in the cloud.\n",
      "\n",
      "5. **Customization and Control**: You have full control over the environment and can tailor it to your specific needs without depending on third-party providers' APIs or policies.\n",
      "\n",
      "6. **Resource Utilization**: Local machines can be optimized for specific tasks, potentially leading to better resource utilization compared to generic cloud instances that might not fully utilize their resources due to shared infrastructure constraints.\n",
      "\n",
      "7. **Scalability and Flexibility**: Depending on the local hardware, you can scale up or down more easily without being constrained by cloud provider limitations.\n",
      "\n",
      "However, it's important to note that running AI models locally also comes with certain challenges such as managing hardware upgrades, software maintenance, and ensuring that the model remains efficient and up-to-date.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate\n",
    ")\n",
    "\n",
    "systemMessage = SystemMessagePromptTemplate.from_template(\"You are an LLM expert\")\n",
    "humanMessage = HumanMessagePromptTemplate.from_template(\"What is the advantage of running AI Models in {env}\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    systemMessage, \n",
    "    humanMessage\n",
    "])\n",
    "\n",
    "# 1 way of doing it\n",
    "# prompt_template = ChatPromptTemplate([\n",
    "#     (\"system\", \"You are an LLM expert\"),\n",
    "#     (\"user\", \"What is the advantage of running AI Models in {env}\")\n",
    "# ])\n",
    "\n",
    "prompt_template\n",
    "\n",
    "prompt = prompt_template.invoke({\"env\": \"local machine\"})\n",
    "\n",
    "# print(prompt)\n",
    "\n",
    "content = llm.invoke(prompt).content\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MessagePlaceHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n",
      " a\n",
      " Large\n",
      " Language\n",
      " Model\n",
      " (\n",
      "LL\n",
      "M\n",
      ")\n",
      " on\n",
      " your\n",
      " local\n",
      " machine\n",
      " offers\n",
      " several\n",
      " advantages\n",
      ",\n",
      " but\n",
      " it\n",
      " also\n",
      " comes\n",
      " with\n",
      " some\n",
      " trade\n",
      "-offs\n",
      ".\n",
      " Here\n",
      " are\n",
      " some\n",
      " key\n",
      " benefits\n",
      ":\n",
      "\n",
      "\n",
      "1\n",
      ".\n",
      " **\n",
      "Privacy\n",
      " and\n",
      " Security\n",
      "**:\n",
      " Running\n",
      " an\n",
      " L\n",
      "LM\n",
      " locally\n",
      " can\n",
      " enhance\n",
      " privacy\n",
      " since\n",
      " you\n",
      " don\n",
      "'t\n",
      " have\n",
      " to\n",
      " send\n",
      " your\n",
      " data\n",
      " to\n",
      " external\n",
      " servers\n",
      ".\n",
      " This\n",
      " is\n",
      " particularly\n",
      " important\n",
      " when\n",
      " dealing\n",
      " with\n",
      " sensitive\n",
      " or\n",
      " confidential\n",
      " information\n",
      ".\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " **\n",
      "Control\n",
      " and\n",
      " Custom\n",
      "ization\n",
      "**:\n",
      " With\n",
      " a\n",
      " local\n",
      " model\n",
      ",\n",
      " you\n",
      " have\n",
      " complete\n",
      " control\n",
      " over\n",
      " the\n",
      " environment\n",
      ",\n",
      " which\n",
      " allows\n",
      " for\n",
      " more\n",
      " customization\n",
      " of\n",
      " settings\n",
      " such\n",
      " as\n",
      " input\n",
      " handling\n",
      ",\n",
      " output\n",
      " formatting\n",
      ",\n",
      " and\n",
      " error\n",
      " management\n",
      " according\n",
      " to\n",
      " your\n",
      " specific\n",
      " needs\n",
      ".\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " **\n",
      "Offline\n",
      " Access\n",
      "**:\n",
      " You\n",
      " can\n",
      " use\n",
      " the\n",
      " L\n",
      "LM\n",
      " even\n",
      " when\n",
      " there\n",
      " is\n",
      " no\n",
      " internet\n",
      " connection\n",
      ",\n",
      " making\n",
      " it\n",
      " useful\n",
      " in\n",
      " environments\n",
      " where\n",
      " connectivity\n",
      " might\n",
      " be\n",
      " unreliable\n",
      " or\n",
      " restricted\n",
      ".\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      " **\n",
      "Resource\n",
      " Management\n",
      "**:\n",
      " You\n",
      " have\n",
      " full\n",
      " control\n",
      " over\n",
      " the\n",
      " computational\n",
      " resources\n",
      " (\n",
      "CPU\n",
      ",\n",
      " GPU\n",
      ")\n",
      " that\n",
      " the\n",
      " model\n",
      " uses\n",
      ".\n",
      " This\n",
      " allows\n",
      " for\n",
      " better\n",
      " optimization\n",
      " and\n",
      " potentially\n",
      " more\n",
      " efficient\n",
      " use\n",
      " of\n",
      " hardware\n",
      " compared\n",
      " to\n",
      " cloud\n",
      "-based\n",
      " services\n",
      ".\n",
      "\n",
      "\n",
      "5\n",
      ".\n",
      " **\n",
      "Cost\n",
      "-\n",
      "Effect\n",
      "iveness\n",
      "**:\n",
      " Running\n",
      " a\n",
      " model\n",
      " locally\n",
      " can\n",
      " be\n",
      " cheaper\n",
      " than\n",
      " using\n",
      " cloud\n",
      " services\n",
      ",\n",
      " especially\n",
      " if\n",
      " you\n",
      " are\n",
      " not\n",
      " running\n",
      " it\n",
      " continuously\n",
      " or\n",
      " require\n",
      " high\n",
      "-performance\n",
      " computing\n",
      " power\n",
      " only\n",
      " occasionally\n",
      ".\n",
      "\n",
      "\n",
      "6\n",
      ".\n",
      " **\n",
      "Custom\n",
      " Training\n",
      " and\n",
      " Tun\n",
      "ing\n",
      "**:\n",
      " You\n",
      " can\n",
      " train\n",
      " the\n",
      " L\n",
      "LM\n",
      " on\n",
      " your\n",
      " local\n",
      " data\n",
      " or\n",
      " fine\n",
      "-t\n",
      "une\n",
      " existing\n",
      " models\n",
      " to\n",
      " better\n",
      " suit\n",
      " specific\n",
      " tasks\n",
      " or\n",
      " domains\n",
      " without\n",
      " relying\n",
      " on\n",
      " external\n",
      " resources\n",
      ".\n",
      "\n",
      "\n",
      "However\n",
      ",\n",
      " there\n",
      " are\n",
      " also\n",
      " some\n",
      " disadvantages\n",
      " to\n",
      " consider\n",
      ":\n",
      "\n",
      "\n",
      "1\n",
      ".\n",
      " **\n",
      "Comput\n",
      "ational\n",
      " Resources\n",
      "**:\n",
      " Local\n",
      " machines\n",
      " may\n",
      " not\n",
      " have\n",
      " the\n",
      " same\n",
      " level\n",
      " of\n",
      " computational\n",
      " power\n",
      " as\n",
      " cloud\n",
      " services\n",
      ",\n",
      " which\n",
      " could\n",
      " limit\n",
      " the\n",
      " size\n",
      " and\n",
      " complexity\n",
      " of\n",
      " the\n",
      " L\n",
      "LM\n",
      " you\n",
      " can\n",
      " run\n",
      " effectively\n",
      ".\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " **\n",
      "Sc\n",
      "al\n",
      "ability\n",
      " Issues\n",
      "**:\n",
      " Scaling\n",
      " up\n",
      " a\n",
      " model\n",
      " or\n",
      " handling\n",
      " very\n",
      " large\n",
      " datasets\n",
      " might\n",
      " be\n",
      " more\n",
      " challenging\n",
      " on\n",
      " local\n",
      " hardware\n",
      " compared\n",
      " to\n",
      " cloud\n",
      " solutions\n",
      " that\n",
      " offer\n",
      " scalable\n",
      " resources\n",
      ".\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " **\n",
      "Maintenance\n",
      " and\n",
      " Updates\n",
      "**:\n",
      " Keeping\n",
      " the\n",
      " software\n",
      " and\n",
      " dependencies\n",
      " up\n",
      "-to\n",
      "-date\n",
      " can\n",
      " be\n",
      " more\n",
      " complex\n",
      " in\n",
      " a\n",
      " local\n",
      " environment\n",
      ",\n",
      " especially\n",
      " if\n",
      " multiple\n",
      " users\n",
      " are\n",
      " involved\n",
      ".\n",
      "\n",
      "\n",
      "4\n",
      ".\n",
      " **\n",
      "Storage\n",
      " Requirements\n",
      "**:\n",
      " Large\n",
      " models\n",
      " require\n",
      " significant\n",
      " storage\n",
      " space\n",
      ",\n",
      " which\n",
      " could\n",
      " be\n",
      " a\n",
      " limitation\n",
      " for\n",
      " machines\n",
      " with\n",
      " limited\n",
      " disk\n",
      " capacity\n",
      ".\n",
      "\n",
      "\n",
      "Overall\n",
      ",\n",
      " running\n",
      " an\n",
      " L\n",
      "LM\n",
      " locally\n",
      " is\n",
      " beneficial\n",
      " when\n",
      " you\n",
      " need\n",
      " privacy\n",
      ",\n",
      " control\n",
      ",\n",
      " or\n",
      " cost\n",
      "-effect\n",
      "iveness\n",
      ",\n",
      " but\n",
      " it\n",
      " may\n",
      " not\n",
      " be\n",
      " the\n",
      " best\n",
      " choice\n",
      " for\n",
      " high\n",
      "-performance\n",
      " requirements\n",
      " or\n",
      " large\n",
      "-scale\n",
      " applications\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 1 way of doing it\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an LLM expert\"),\n",
    "    (\"placeholder\", \"{msg}\")\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({\"msg\": [HumanMessage(\"What is the advantage of running LLM in local machine\")]})\n",
    "\n",
    "for str in llm.stream(prompt):\n",
    "    print(str.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
