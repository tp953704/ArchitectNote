# GKE 节点污点(Taints)与Pod容忍(Tolerations)实战指南
> 实验目标
> 本实验演示如何在GKE集群中管理节点污点，并通过Pod容忍配置实现工作负载的精确调度。

实验步骤
## 步骤1：创建带污点的集群
```
gcloud container clusters create gke-deep-dive
--num-nodes=1
--disk-type=pd-standard
--disk-size=10
--node-taints function=research:PreferNoSchedule
```
关键参数说明：
```
--node-taints：设置初始节点污点
PreferNoSchedule：尽量不调度，非强制
```
## 步骤2：验证节点配置
```
kubectl get nodes
kubectl describe node <node-name>
```
预期输出：在节点描述中应看到：
```
Taints: function=research:PreferNoSchedule
```
## 步骤3：创建无污点的节点池
```
gcloud container node-pools create gke-deep-dive-pool
--num-nodes=1
--disk-type=pd-standard
--disk-size=10
--cluster gke-deep-dive
```
重要特性：新节点池不会继承集群级别的污点设置

## 步骤4：更新节点池添加污点
```
gcloud beta container node-pools update gke-deep-dive-pool
--node-taints="function=shared:NoSchedule"
--cluster=gke-deep-dive
```
### 污点效果说明：
- NoSchedule：禁止调度不容忍的Pod
- PreferNoSchedule：尽量不调度
- NoExecute：驱逐不容忍的现有Pod

## 步骤5：创建专用节点池
```
gcloud container node-pools create gke-deep-dive-pool-dedicated
--num-nodes=1
--disk-type=pd-standard
--disk-size=10
--cluster gke-deep-dive
--node-taints dedicated=development:NoExecute
```
## 步骤6：配置容忍污点的Pod
```
apiVersion: v1
kind: Pod
metadata:
name: shared-pod
spec:
containers:
    name: shared-pod
    image: nginx
tolerations:
    key: "function"
    operator: "Equal"
    value: "shared"
    effect: "NoSchedule"
```
部署命令：
```
kubectl apply -f shared-pod.yaml
```
## 步骤7：更新默认节点池污点
```
gcloud beta container node-pools update default-pool
--node-taints="function=research:NoSchedule"
--cluster=gke-deep-dive
```
## 步骤9：部署无容忍配置的Pod
```
apiVersion: v1
kind: Pod
metadata:
name: dedicated-pod
spec:
containers:
    name: dedicated-pod
    image: nginx
```
部署命令：
```
kubectl apply -f dedicated-pod.yaml
```
## 步骤10：观察Pod状态
```
kubectl get pods -o wide
```
预期现象：
- shared-pod：运行在gke-deep-dive-pool节点
- dedicated-pod：可能处于Pending状态

## 步骤11：移除节点污点
```
kubectl taint nodes <node-name> function-
```
## 步骤12：再次观察Pod状态
```
kubectl get pods -o wide
```
预期变化：
- 之前Pending的Pod现在可以调度到已清除污点的节点

## 关键概念总结
```
污点(Taint)类型对比
类型	调度影响	对现有Pod影响	典型场景
NoSchedule	禁止新Pod调度	不影响	专用硬件节点
PreferNoSchedule	尽量避免调度	不影响	优选隔离
NoExecute	禁止新Pod调度	驱逐不容忍Pod	关键维护期
```
## 最佳实践建议
### 生产环境建议：
1. 使用NoSchedule而非PreferNoSchedule确保严格隔离
2. 为关键工作负载配置专用节点池
- 标签配合策略：
```
spec:
nodeSelector:
dedicated: "true"
tolerations:
    key: "dedicated"
    operator: "Exists"
```
调试技巧：
```
查看调度失败原因
kubectl describe pod <pending-pod-name>

查看节点容量
kubectl describe nodes | grep -A 10 "Allocatable"
```
## 自动扩缩容注意事项：
1. 节点池更新操作可能导致临时不可用
2. 建议在低峰期执行污点变更

