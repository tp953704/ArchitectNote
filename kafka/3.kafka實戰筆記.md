# Kafka 食物筆記筆記

這份筆記旨在幫助你深入理解 Apache Kafka 的核心概念、架構以及實際應用。無論你是初學者還是有一定經驗的開發者，都能從中獲益。

## 核心比喻：一個超級郵局系統

想像 Kafka 是一個全球最大、效率最高的郵局系統。傳統郵局是寄信給特定的人，但 Kafka 這個超級郵局是基於「訂閱主題」的。

*   你不是把信寄給「張三」，而是寄到「財經新聞」這個信箱（主題）。
*   所有對「財經新聞」感興趣的人（訂閱者）都會收到這封信的副本。

現在，讓我們基於這個比喻來認識 Kafka 的核心元件。

## 1. 核心元件 (Core Components)

*   **Producer (生產者)**
    *   **職責**: 負責發布訊息到 Kafka 的 Topic (主題) 中。
    *   **比喻**: 任何想要寄信的人。他們寫好信的內容，然後決定這封信要投到哪個主題的信箱。生產者可以決定訊息要發到哪個分區，例如輪詢或基於某個 key 來分配。

*   **Consumer (消費者)**
    *   **職責**: 從 Kafka 的 Topic 訂閱並讀取訊息。
    *   **比喻**: 訂閱了特定主題信箱的人。例如，所有訂閱「財經新聞」的人都會去這個主題的信箱收信。

*   **Broker (代理節點)**
    *   **職責**: Kafka 叢集中的一台伺服器。 它負責儲存訊息、處理來自生產者和消費者的請求。 多個 Broker 組成一個高可用的 Kafka 叢集。
    *   **比喻**: 一間間獨立的郵局。整個郵政系統由許多家郵局（Brokers）組成，共同分擔工作。

*   **Topic (主題)**
    *   **職責**: 訊息的分類。所有訊息都必須發布到一個 Topic。 它是邏輯上的概念，用來區分不同類型的數據流。
    *   **比喻**: 郵局裡不同主題的信箱，例如「體育新聞」、「科技動態」或「生活快訊」。

*   **Partition (分區)**
    *   **職責**: 這是 Kafka 實現擴展性和並行處理的關鍵。 每個 Topic 可以被分成一個或多個 Partition，訊息實際上是儲存在 Partition 裡的。 每個分區都是一個有序的、不可變的訊息序列。
    *   **比喻**: 由於「財經新聞」這個主題太熱門，信件太多，郵局決定開設多個處理櫃台（Partitions）來分流。每個櫃台只處理一部分信件，從而加快了整體速度。

*   **Offset (偏移量)**
    *   **職責**: Partition 中每條訊息的唯一識別碼，是一個從 0 開始遞增的數字。 消費者通過 Offset 來追蹤自己讀到了哪個位置。
    *   **比喻**: 每個櫃台（Partition）裡的每封信都有一個獨一無二的編號（Offset）。當你讀完第 10 封信，你只要記住下一次從第 11 封開始讀就行。

*   **Consumer Group (消費者群組)**
    *   **職責**: 一個或多個消費者組成的群組，共同消費一個 Topic。 Kafka 會將 Topic 的每個 Partition 只分配給群組中的一個消費者，從而實現負載均衡。
    *   **比喻**: 為了更快地處理「財經新聞」的所有信件，你找了幾個朋友組成一個讀信小組（Consumer Group）。郵局（Kafka）會確保每個櫃台（Partition）的信只會被小組中的一個人讀取，避免了重複工作。

## 2. 工作流程 (Workflow)

1.  **啟動與協調**: Kafka 叢集中的 Broker 啟動後，會透過一個協調服務（早期版本使用 ZooKeeper，新版本使用內建的 KRaft）來選舉出一個 Controller Broker。 這個 Controller 負責管理叢集的狀態，例如誰是 Leader。
2.  **生產者發送訊息**:
    *   生產者決定向 `my-topic` 發送一條訊息。
    *   它會從 Kafka 叢集獲取元數據，知道 `my-topic` 有哪些分區，以及每個分區的 Leader Broker 在哪裡。
    *   生產者直接將訊息發送給對應分區的 Leader Broker。
3.  **Broker 儲存訊息**:
    *   Leader Broker 收到訊息後，將其追加到 Partition 的末尾，並為其分配一個新的 Offset。
    *   該分區的其他副本（Follower Replicas）會從 Leader 拉取這條訊息，以保持數據同步。
4.  **消費者消費訊息**:
    *   一個消費者群組訂閱了 `my-topic`。
    *   Kafka 會將 `my-topic` 的分區分配給群組內的消費者。例如，P0 分配給 C1，P1 分配給 C2，P2 也分配給 C1。
    *   每個消費者會從自己被分配到的分區 Leader Broker 拉取訊息。
    *   消費者處理完訊息後，會定期向 Kafka "提交" (commit) 它已經處理到的 Offset，這樣即使消費者崩潰重啟，也能從上次的位置繼續消費。

## 3. Kafka 的主要優勢

*   **高吞吐量**: 透過分區、批次發送、順序讀寫磁碟等技術，Kafka 可以處理極高的訊息量。
*   **高可用性與持久性**: 訊息被持久化到磁碟，並且透過副本機制（Replication），即使某個 Broker 故障，數據也不會丟失。
*   **可擴展性**: 可以透過增加 Broker 或為 Topic 增加分區來水平擴展整個系統的處理能力。
*   **解耦合**: 生產者和消費者完全分離，它們只關心 Topic，不需要知道對方的存在，使得系統架構更加靈
活。

## 4. Kafka Streams 深入探討

Kafka 不僅僅是一個訊息佇列，它還提供了一個強大的函式庫 **Kafka Streams**，讓你可以直接在 Kafka 中進行即時的資料處理和轉換。

### 4.1 核心概念

*   **Topology (拓撲)**: 這是 Kafka Streams 應用程式的核心。它定義了資料處理的流程，就像一個由各種處理節點組成的流程圖。你可以透過 `StreamsBuilder` 來建立一個拓撲。

*   **SerDes (Serializer/Deserializer)**: Kafka Streams 處理的是各種格式的資料。為了讓 Java 應用程式能夠理解這些資料，你需要提供對應的序列化器 (Serializer) 和反序列化器 (Deserializer)。
    *   **POJO (Plain Old Java Object)**: 在實際應用中，我們通常會將訊息轉換成 Java 物件來處理。
    *   **Schema Definition**: 為了方便管理，我們可以使用 JSON Schema 或 Avro Schema 來定義訊息的格式，並自動生成對應的 POJO 類別。

### 4.2 為何 SerDes 如此重要？

在 Kafka Streams 中，許多操作都需要 `SerDes`：

*   **Source/Sink Processor**: 當資料從 Kafka Topic 讀取或寫入時，需要 `SerDes` 來進行轉換。
*   **Stateful Operations**: 像 `table()`, `through()`, `groupBy()` 這些需要將中間狀態保存到 Kafka Topic 的操作，也都需要 `SerDes`。

因此，為你的資料提供正確的 `SerDes` 是開發 Kafka Streams 應用程式的關鍵步驟。

## 5. 總結

Kafka 是一個功能強大且靈活的分散式串流平台。透過理解其核心概念，並善用 Kafka Streams，你可以建構出高效、可靠的即時資料處理應用。

希望這份筆記能幫助你更好地掌握 Kafka！
