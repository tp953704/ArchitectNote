好的，這部分是關於「系統性能」模組的詳細課程大綱，以下是為你整理的中文筆記：

---

### **系統性能模組：課程大綱總覽**

本模組將分為三個主要部分，從理解性能、到降低延遲、最後提升吞吐量。

#### **第一部分：理解性能基礎**
1.  **什麼是性能？**
    *   了解性能問題的具體表現形式。
2.  **如何衡量性能？**
    *   學習評估系統性能的關鍵指標。
3.  **性能取決於哪些原則？**
    *   掌握影響系統性能的根本性原則。

#### **第二部分：核心設計與優化 - 如何最小化延遲**
這部分是優化性能的重點，主要從四個核心面向著手，目標是**減少請求的處理時間**：

1.  **最大化 CPU 利用率**
    *   確保 CPU 高效工作，不閒置。
2.  **最小化記憶體相關延遲**
    *   優化記憶體存取與管理，減少等待時間。
3.  **最小化網路傳輸延遲**
    *   優化資料在網路上的傳輸效率。
4.  **改善磁碟利用率與最小化磁碟延遲**
    *   優化磁碟 I/O，因為磁碟通常是系統中最慢的環節之一。

#### **第三部分：提升系統吞吐量**
這部分的目標是讓系統在**單位時間內能處理更多請求**，主要聚焦於：

1.  **併發**
    *   透過同時處理多個請求來提高總處理量。
2.  **鎖定**
    *   深入探討「鎖」對性能的關鍵影響。
    *   **悲觀鎖定**：何時與為何使用。
    *   **樂觀鎖定**：何時與為何使用。
    *   理解「一致性」在性能中扮演的角色。
3.  **快取**
    *   **靜態資料快取**：如何快取不常變動的資料。
    *   **動態資料快取**：如何快取經常變動的資料。
    *   快取所帶來的挑戰與其對性能的助益。

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# 詳細筆記 — 系統效能設計與優化

下面把講師內容整理成結構化、可操作的筆記，方便學習與實務應用（以你給的範例系統為主：Web 應用 → 服務 → RDBMS，外加批次報表元件）。

---

# 1. 範例系統架構（參考）

* Web 應用（瀏覽器端）
  ↳ 呼叫
* 業務服務（service）
  ↳ 存取
* 關聯式資料庫（RDBMS）
* 報表/批次處理元件（Batch）：讀 DB → 計算/處理 → 寫回 DB 或檔案

---

# 2. 「效能」的定義

* **效能（Performance）**：在固定的工作負載（workload）與硬體（hardware）下，系統回應的速度與穩定性。

  * 重要：測量需固定工作負載與硬體，否則比較無意義。
* 主要目標：

  * **最小化延遲（latency）** — 單次請求的等待 + 處理時間
  * **最大化吞吐量（throughput）** — 單位時間內處理的請求數（受 latency 與 capacity 共同影響）

---

# 3. 效能問題的本質（排隊觀點）

* 所有效能問題都可以看成**某處排隊（queue）累積**（例如：網路 socket、DB 請求隊列、OS run queue、I/O 等）。
* 排隊現象像交通阻塞：請求被卡住、無法前進 → 延遲上升、tail latency 惡化。

造成排隊的三大類原因：

1. **處理不當 / 非效率演算法**（slow processing）

   * 長時間 CPU/IO 作業、O(n²) 演算法、低效 DB query。
2. **序列化的資源存取**（serial resource access）

   * 鎖（locks）、臨界區、單一資源必須逐一存取（例如：同一帳戶的存款/提款必須序列化）。
3. **資源容量限制**（limited capacity）

   * CPU、記憶體、IO、網路頻寬、DB 連線數不足等。

---

# 4. 設計效能的三大原則

1. **效率（Efficiency）** — 針對單一請求（serial request）

   * 專注：減少單一請求的處理時間（processing time）。
2. **併發性（Concurrency）** — 針對多個同時請求（concurrent requests）

   * 專注：減少因互相競爭資源而造成的等待時間（queuing & coherence）。
3. **容量（Capacity）** — 提供足夠硬體資源

   * 專注：在需要時透過擴容解決瓶頸（scale up / scale out）。

> 講師重點：課程重心放在**效率**（單請求）與**併發**（多請求）的設計與優化，容量屬於補救或最後手段。

---

# 5. 效率（單請求）要素

要讓單一請求快，關鍵項目：

* **資源使用效率（CPU / Memory / IO / Network / Disk）**
* **演算法與邏輯**：選用更低複雜度的演算法、避免多餘計算。
* **資料結構與 DB Schema**：

  * 程式內使用合適資料結構（map vs list 等）。
  * DB 端使用正確的索引、避免全表掃描（full table scan）。
* **快取（Caching）**：

  * 本地快取、分散式快取（Redis、Memcached）等。改動少但能帶來大量效能改善。

---

# 6. 併發（Concurrency）要素

* 併發關注點（pure concurrency concerns）：

  * **Queuing**：多請求競爭同資源造成的等待（例：worker pool 被耗盡、DB 連線耗盡）。
  * **Coherence / Contention**：鎖、同步機制、共享狀態一致性造成的瓶頸。
* 需要系統層（OS/Runtime）與程式設計上的支持（非阻塞 I/O、非同步處理、適當的鎖設計、避免全域鎖）。

---

# 7. 容量（Capacity）觀點

* 若瓶頸是硬體資源（CPU / memory / disk / network），**升級硬體或擴充（scale up / scale out）** 可改善效能。
* 但**在投資硬體前**應先確認是否為容量限制（透過監控/測試），否則會浪費資源。

---

# 8. 衡量效能的四大指標（必測）

1. **Latency（延遲）** — 單次請求所耗時間（影響使用者體驗）
2. **Throughput（吞吐）** — 每秒或每分鐘處理請求數（影響系統可支援的使用者數）
3. **Errors（錯誤率）** — 功能性錯誤或超時（功能錯誤會使測試結果無效）
4. **Resource Saturation（資源飽和度）** — CPU/IO/Memory/Network 等使用率（是否達到 100%）

---

# 9. Tail Latency（尾端延遲）

* **定義**：在分布中位於尾端的高延遲值（常用 95%、99%、99.9% 等百分位衡量）。
* **為何重要**：

  * 平均值可能掩蓋少數極端慢的請求（但這些對使用者體驗或 SLA 可能非常關鍵）。
  * 尾端延遲常是排隊效應（queuing）或突發資源競爭的結果。若有顯著 tail latency，代表在提高負載時情況會惡化。
* **測量**：報告至少平均延遲以及 95% / 99%（或 99.9%）延遲。
* **SLA 建議**：根據業務需求設定 99% 或 99.9% 閾值（例如：99% < 3000ms）。

---

# 10. 如何定位與排查效能問題（實務流程）

1. **監控（Observability）**：收集 latency、throughput、errors、資源使用（CPU、memory、disk I/O、network）、DB 指標（慢查詢、連線數）與應用端指標（GC、thread pool）
2. **再現/負載測試（Load Test）**：以模擬流量產生負載（找出瓶頸、觀察 tail latency）
3. **剖析（Profiling）**：CPU/Memory/IO profile，找出慢函式、熱點（hot path）
4. **審查 DB**：慢查詢、缺索引、鎖等待（locks / deadlocks）、連線池耗盡
5. **檢查資源競爭**：鎖、同步、全域單點（single-threaded components）
6. **檢查網路與 I/O**：socket backlog、長連線、頻寬瓶頸
7. **驗證 Tail Latency**：分析百分位分布，找出導致尾端慢的因素（批次作業、GC 暫停、惡劣查詢）

---

# 11. 常見優化手段（具體且實務）

## A. 應用層（業務服務 / Web）

* **快取**：資料快取（Redis）、頁面/片段快取、結果快取、query result cache。
* **非同步化 / 背景處理**：把非即時工作（email、報表、長時間處理）放到背景工作隊列（隊列系統如 RabbitMQ、Kafka、Beanstalk）以減少同步延遲。
* **減少同步呼叫（外部 API / DB）**：批次化、小心 retry/backoff。
* **演算法與資料結構優化**：降低時間複雜度、避免重複計算。
* **連線與執行緒調校**：適當的 thread pool / worker pool 大小、避免 thread oversubscription。
* **非阻塞 I/O / Reactor / async frameworks**：在大量 I/O-bound 請求時使用非阻塞模型（例如：Netty、async servlet、node.js 類型）。

## B. DB 層（RDBMS）

* **索引（Indexing）**：針對常用查詢建立合適索引，避免全表掃描。
* **查詢優化**：檢查執行計畫、避免 N+1 問題、limit 避免過多資料回傳。
* **連線池管理**：合理配置最大連線數、連線重用。
* **分區 / 分表（Sharding / Partitioning）**：當資料量大時分散負載。
* **寫入優化**：批次插入（bulk insert）、延遲寫入（如果可接受）。

## C. 基礎設施與容量

* **水平擴展（scale-out）**：多節點負載分流（Stateless services 易水平擴展）。
* **垂直擴展（scale-up）**：提升 CPU / memory / faster disks（短期方案）。
* **CDN / 靜態資源外放**：減少 Web 服務負載。
* **資源隔離**：把批次作業與線上流量隔離，避免互相影響（不同時間窗或不同資源池）。

## D. 併發 / 同步策略

* **縮小鎖範圍 / 使用更細粒度鎖**：避免全域鎖導致串行化。
* **無鎖資料結構 / CAS**：在適合情況下使用 lock-free approach。
* **樂觀鎖 vs 悲觀鎖**：評估並發衝突頻率選擇正確策略。

---

# 12. 測試與指標建議（實作）

* **必建測試**：

  * 負載測試（Load / Stress / Soak test）
  * 壓力測試（找到系統崩潰點）
  * 配置變動測試（不同 thread pool / conn pool / cache hit rate）
* **監控指標（最低）**：

  * 平均 / p50 / p95 / p99 latency
  * Throughput（req/s）
  * Error rate（%）
  * CPU、Memory、Disk I/O、Network 使用率
  * DB slow queries / connections / locks
  * GC pause 時間（若使用 JVM）
* **SLO/SLA 範例**：

  * p99 latency < 3000ms（或根據業務需求設定）
  * error rate < 0.1%
  * 系統可用率 > 99.9%

---

# 13. 具體檢查清單（排查時用）

1. 監控是否顯示 CPU/IO/Memory 飽和？（若是 → capacity 或優化 IO/記憶體使用）
2. 是否有大量慢查詢或 DB 鎖等待？（若是 → 索引 / query 优化 / connection pool）
3. 是否有大量同步呼叫或等待外部 API？（若是 → 非同步 / timeout 與重試策略）
4. 是否出現大量 thread / socket backlog？（若是 → thread pool / socket 調校）
5. 是否 tail latency 明顯？是哪一類請求占多數？（分析 99% / 99.9%）
6. 是否某些操作被序列化（global lock / single-threaded component）？（若是 → 重構為可併發或拆分）

---

# 14. 對範例系統的建議（優先級）

1. **先監控＋量化**（必做） — 收集 latency 分佈、p99、throughput、DB 指標。
2. **優化 DB（若為瓶頸）**：慢查詢分析、建立/修正索引、連線池設定。
3. **加入快取**：熱門查詢或不常變更資料先用快取（Redis），大幅降低 DB 負載。
4. **把可延遲工作移到批次/背景**：提高線上請求吞吐。
5. **避免全域鎖與序列化熱點**：檢視業務邏輯是否強制序列化；若可，改用樂觀策略或分片。
6. **針對 tail latency 做分級處理**：設計 graceful degradation、circuit breaker、timeout、priority queues。
7. **做負載測試與容量規劃**：模擬峰值流量並觀察系統表現，決定是否需 scale out。

---

# 15. 小結（關鍵要記）

* 所有效能問題可視為「排隊」問題（queue buildup）；找出在哪裡排隊、為何排隊、如何移除/緩解。
* 三原則：**效率（單請求）**、**併發（多請求）**、**容量（資源）**。
* 測得不只平均值，**一定要看尾端延遲（p95/p99/p99.9）**，它能事先警示在負載增加時效能會如何惡化。
* 優化路徑通常先從**減少延遲（軟體層面）**做起，再視情況做**擴容（硬體）**。

# 系統效能優化筆記：降低延遲與提升併發

## 1. 網路延遲優化

### 網路延遲來源
- **資料傳輸延遲**：資料在實體線路上的傳輸時間
- **連線建立開銷**：
  - TCP連線：1次往返時間(RTT)
  - SSL/TLS連線：3次往返時間(RTT)

### 連線建立優化策略
- **連線池(Connection Pool)**：
  - Web應用程式與REST應用程式之間
  - 業務應用程式與資料庫之間
- **持久連線(Persistent Connections)**：
  - HTTP/1.1預設支援
  - 瀏覽器與伺服器之間的重複使用
- **SSL會話快取**：減少SSL握手階段的往返次數

### 資料傳輸優化策略
- **資料快取**：
  - 靜態資料快取（瀏覽器端）
  - 使用者會話資料快取
  - 資料庫查詢結果快取
- **高效資料格式**：
  - 內部網路可使用二進位協定（gRPC、Thrift）
  - 權衡：效能 vs 互通性
- **資料壓縮**：
  - 伺服器端與客戶端皆可壓縮
  - CPU開銷遠小於網路傳輸開銷

## 2. 記憶體延遲優化

### 記憶體相關效能問題
- **有限堆記憶體**：程序崩潰風險
- **大堆記憶體**：
  - 記憶體交換(Swapping)導致效能下降
  - 垃圾回收器工作負載增加
- **垃圾回收演算法選擇不當**
- **資料庫緩衝記憶體不足**

### 記憶體優化策略
- **避免記憶體膨脹**：
  - 減少不必要的物件配置
  - 保持較小的程式碼庫
- **弱引用與軟引用(Weak/Soft References)**：
  - 記憶體不足時可被垃圾回收器回收
- **多個小程序優於單一大程序**：
  - 避免超大堆記憶體導致的GC效率問題
- **垃圾回收器選擇**：
  - 批次處理：追求總體效率，可接受暫停
  - 即時服務：追求低延遲，減少暫停時間
- **資料庫緩衝記憶體優化**：
  - 適當的記憶體配置
  - 正規化減少資料重複
  - 計算代替儲存（減少緩衝記憶體使用）

## 3. 磁碟延遲優化

### 磁碟I/O特性
- **順序存取** vs **隨機存取**：順序存取快得多
- **日誌寫入**：順序寫入，相對高效

### 日誌優化策略
- **批次日誌記錄**：減少上下文切換
- **非同步日誌記錄**：
  - 主執行緒專注處理業務邏輯
  - 日誌寫入委託給專門執行緒
  - 權衡：可能遺失最後幾條日誌記錄

### 網頁內容優化
- **反向代理(Reverse Proxy)**：
  - 分離靜態與動態內容處理
  - 專門處理靜態檔案（圖片、CSS、JS）
  - 利用記憶體快取與頁面快取
  - 零拷貝技術優化
- **範例工具**：Varnish、Nginx

### 資料庫磁碟存取優化
- **快取策略**：減少資料庫查詢
- **正規化與反正規化權衡**：
  - 一般情況：正規化節省記憶體
  - 磁碟I/O成為瓶頸時：考慮反正規化
- **索引優化**：
  - 避免全表掃描
  - 精準定位資料磁碟位置
- **查詢優化**：減少資料擷取量
- **硬體層級優化**：
  - 固態硬碟(SSD)
  - 高IOPS硬碟
  - RAID架構（條帶化與鏡像）

## 4. CPU延遲優化

### CPU延遲原因
- **低效演算法**
- **上下文切換(Context Switching)**：
  - 程序/執行緒切換的開銷
  - I/O操作導致的CPU空轉

### 優化策略
- **高效演算法與查詢**
- **批次I/O與非同步I/O**：
  - 合併多個資料庫呼叫
  - 減少上下文切換次數
- **單執行緒模型**：
  - 範例：Node.js、Nginx、Redis
  - 主執行緒處理所有請求
  - I/O操作委託給非同步執行緒
  - 避免主執行緒的上下文切換
- **執行緒池大小優化**：
  - 避免過多執行緒導致CPU飢餓
  - 根據I/O密集度與CPU密集度調整
- **虛擬化環境隔離**：
  - 為關鍵程序分配專用CPU配額
  - 避免程序間相互干擾

## 5. 延遲數字對比

### 各層級延遲比較（2012年基準）
- **CPU操作**：0.5-7奈秒
- **CPU鎖操作**：25奈秒
- **主記憶體存取**：100奈秒
- **同資料中心網路呼叫**：500微秒
- **網際網路呼叫**：150毫秒（300倍於區域網路）
- **磁碟尋道**：10毫秒
- **順序讀取1MB資料**：
  - 傳統硬碟：20毫秒
  - SSD：1毫秒（20倍提升）
- **記憶體隨機存取**：250奈秒
- **記憶體順序存取**：100奈秒
- **資料壓縮**：
  - 壓縮1KB資料：3微秒
  - 1Gbps網路傳輸1KB：10微秒

### 關鍵洞察
1. **順序存取遠優於隨機存取**
2. **記憶體存取比磁碟快數個數量級**
3. **區域網路呼叫比網際網路快300倍**
4. **壓縮開銷遠小於網路傳輸開銷**
5. **SSD可大幅改善磁碟I/O效能**

## 總結

### 序列請求延遲優化重點
1. **網路層**：連線重用、壓縮、快取
2. **記憶體層**：適當堆大小、GC調優、緩衝優化
3. **磁碟層**：順序I/O、快取、索引、SSD
4. **CPU層**：演算法優化、減少上下文切換、適當併發模型

### 後續方向
接下來將專注於**並行請求延遲優化**，重點研究**併發性(Concurrency)** 的相關技術與策略，以處理系統中多個同時發生的請求。

---
# 併發處理 (Concurrent Processing) 完整筆記

## 1. 併發處理基礎概念

### 序列處理 vs 並行處理
- **序列處理**：請求按順序一個接一個處理
- **並行處理**：多個請求同時處理
- **現實系統**：混合模式，部分並行 + 部分序列

### 處理行為對比
```
完美序列系統：
- 吞吐量固定，不隨處理器數量增加
- 圖表：完全平坦

完美並行系統：
- 吞吐量隨處理器數量線性增長
- 圖表：完美直線

現實系統：
- 位於兩者之間
- 受序列部分限制
```

## 2. Amdahl's Law (阿姆達爾定律)

### 核心概念
- **序列部分**是限制系統併發能力的關鍵因素
- 即使很小的序列部分也會嚴重限制最大吞吐量

### 不同序列比例的影響
- **5% 序列部分**：吞吐量可達理想值的約80%
- **10% 序列部分**：吞吐量約為理想值的50%
- **25% 序列部分**：吞吐量嚴重受限
- **50% 序列部分**：接近序列處理性能

### 重要結論
> 要實現高併發性能，必須將序列部分控制在5%以下

## 3. Universal Scalability Law (通用可擴展性定律)

### 兩個限制因素
1. **Queuing (排隊效應)** - Amdahl's Law 已涵蓋
2. **Coherence (一致性效應)** - 新增因素

### Coherence 一致性效應
- **產生原因**：多處理器間共享數據的同步成本
- **表現特徵**：吞吐量隨負載增加而**下降**
- **與 Queuing 的區別**：
  - Queuing：吞吐量趨於平坦
  - Coherence：吞吐量實際下降

## 4. 系統中的競爭點 (Contention Points)

### 主要競爭來源
1. **網路層級**
   - Listen Queue：請求等待接受處理的隊列
   - Accept Queue：請求等待分配線程的隊列

2. **線程層級**
   - Thread Pool：工作線程池競爭
   - Context Switching：上下文切換開銷

3. **後端資源**
   - Connection Pool：數據庫連接池競爭
   - 外部服務調用

4. **硬體資源**
   - CPU、記憶體、磁碟、網路頻寬

5. **鎖競爭**
   - 同步代碼段
   - 共享資源訪問

## 5. 競爭優化策略

### 系統資源優化
- **垂直擴展**：升級硬體配置
- **RAID 磁碟**：實現並行磁碟訪問
- **網路優化**：提高頻寬質量

### 線程池優化
```java
// 線程池大小設定原則
if (高CPU時間 + 低等待時間) {
    // CPU密集型：線程數 ≈ CPU核心數
    threadPoolSize = CPU核心數;
} else if (低CPU時間 + 高等待時間) {
    // IO密集型：可設定較大線程池
    threadPoolSize = CPU核心數 * (1 + 等待時間/CPU時間);
}
```

### 連接池優化
- **基本原則**：連接池大小 ≈ 線程池大小
- **特殊情況**：並行調用需要更多連接

### Listen Queue 優化
- 一般情況下無需特別調整
- 極端規模時調整作業系統參數

## 6. 鎖競爭優化

### 減少鎖持有時間
- 將非關鍵代碼移出同步塊
- 避免在同步塊中執行IO操作

### 鎖粒度優化
1. **鎖拆分 (Lock Splitting)**
   - 將大鎖拆分為多個小鎖
   - 減少競爭範圍

2. **鎖條帶化 (Lock Striping)**
   ```java
   // ConcurrentHashMap 範例
   // 將數據分為16個分區，每個分區獨立鎖定
   ConcurrentHashMap<String, String> map = new ConcurrentHashMap<>();
   ```

### 讀寫鎖 (ReadWrite Lock)
- **讀鎖**：共享，允許多個讀取者
- **寫鎖**：獨佔，只允許一個寫入者
- **適用場景**：讀多寫少的共享數據結構

## 7. 悲觀鎖 vs 樂觀鎖

### 悲觀鎖 (Pessimistic Locking)
```sql
-- 資料庫範例
BEGIN TRANSACTION;
SELECT * FROM inventory WHERE product_id = 1 FOR UPDATE;
-- 處理業務邏輯
UPDATE inventory SET quantity = quantity - 1 WHERE product_id = 1;
COMMIT;
```

**特點**：
- 先取得鎖再處理數據
- 鎖持有時間長
- 適合高競爭場景

### 樂觀鎖 (Optimistic Locking)
```sql
-- 資料庫範例
UPDATE inventory 
SET quantity = quantity - 1 
WHERE product_id = 1 AND quantity = @expected_quantity;

-- 檢查影響行數，如果為0則重試
```

**特點**：
- 先處理後驗證
- 鎖持有時間短
- 適合低至中等競爭場景
- 需要重試機制

## 8. Compare-and-Swap (CAS) 機制

### Java 範例
```java
AtomicInteger atomicInt = new AtomicInteger(10);

// CAS 操作
boolean success = atomicInt.compareAndSet(10, 20);
if (!success) {
    // 重試或處理失敗
}
```

### 資料庫範例 (NoSQL)
```sql
-- Cassandra 範例
UPDATE inventory 
SET quantity = 200 
WHERE product_id = '123' 
IF quantity = 100;
```

**優勢**：
- 硬體層級支持，性能好
- 無需獨佔鎖
- 自動檢測數據衝突

## 9. 死鎖 (Deadlock) 處理

### 排序相關死鎖
```java
// 死鎖範例
// Thread1: lock A -> try lock B
// Thread2: lock B -> try lock A

// 解決方案：全局排序
public void transfer(Account from, Account to) {
    Account first = from.id < to.id ? from : to;
    Account second = from.id < to.id ? to : from;
    
    synchronized(first) {
        synchronized(second) {
            // 轉帳邏輯
        }
    }
}
```

### 負載誘發死鎖
**微服務架構中的典型場景**：
```
用戶 -> 網關 -> 服務A -> 網關 -> 服務B
```
**問題**：所有線程都在等待網關服務，形成循環等待

**解決方案**：
- 適當設定線程池大小
- 實現超時和重試機制
- 避免循環調用

## 10. 一致性延遲 (Coherence Delay)

### 記憶體層級架構
```
CPU寄存器 → L1快取 → L2快取 → 主記憶體
   0.5ns       7ns       100ns
```

### 可見性保證機制
1. **synchronized**：保證鎖定 + 可見性
2. **volatile**：只保證可見性

### 性能影響
- **L1/L2快取訪問**：0.5-7納秒
- **主記憶體訪問**：100納秒（慢15-20倍）
- ** coherence 成本**：強制從主記憶體讀取

### 優化建議
- 最小化共享數據的頻繁訪問
- 適當使用 volatile 替代 synchronized
- 避免不必要的共享狀態

## 總結

### 關鍵要點
1. **識別序列部分**：這是限制併發的主要因素
2. **平衡競爭**：適當設定資源池大小
3. **選擇正確的鎖策略**：根據競爭程度選擇悲觀/樂觀鎖
4. **避免死鎖**：使用全局排序和適當超時
5. **最小化一致性開銷**：謹慎使用共享數據

### 性能優化層級
1. **應用層**：算法優化、鎖策略
2. **系統層**：線程池、連接池配置
3. **硬體層**：垂直擴展、RAID、高速網路
4. **架構層**：服務拆分、負載均衡

通過系統性的併發優化，可以顯著提升系統的吞吐量和響應性能。
---

# 快取策略 (Caching Strategies) 完整筆記

## 1. 快取在系統架構中的位置

### 系統架構回顧
- **持久連線**、**回應壓縮**、**高效編碼**：提升網頁應用效能
- **執行緒池**、**資料庫連線池**：必須使用並優化大小
- **高效鎖定**：適當使用樂觀鎖和悲觀鎖
- **查詢優化**：重要效能提升點
- **非同步日誌記錄**：節省延遲
- **順序和批次 I/O**：提升效率
- **正規化與反正規化**：根據需求選擇

### 快取層級架構
```
用戶端 (瀏覽器)
    ↓
反向代理/負載平衡器 (靜態資料快取)
    ↓
網頁應用 (Session快取、物件快取)
    ↓
服務層 (物件快取)
    ↓
資料庫 (緩衝快取 - 內部管理)
```

## 2. 靜態資料快取 (HTTP Caching)

### 快取位置
1. **瀏覽器快取** (私有快取)
2. **代理伺服器** (公有快取) - 靠近用戶端
3. **反向代理** (私有快取) - 靠近伺服器

### HTTP 快取控制標頭
```http
Cache-Control: public, max-age=3600
ETag: "version-123"
```

### 重要標頭值
- **no-cache**：可快取但必須驗證
- **no-store**：絕對不應快取
- **public**：適合公有快取
- **private**：適合私有快取
- **max-age**：快取有效時間
- **must-revalidate**：超過max-age後必須重新驗證

### ETag 機制
```
瀏覽器請求：If-None-Match: "version-1"
伺服器回應：
   - 304 Not Modified (版本匹配)
   - 200 OK + 新ETag (版本不匹配)
```

## 3. 動態資料快取策略

### 快取位置
- **服務層**：快取從資料庫取得的資料
- **網頁應用**：快取使用者相關資料

### 兩種快取策略

#### 1. 專屬快取 (Exclusive Cache)
```java
// 每個節點維護自己的快取
Map<String, Object> localCache = new ConcurrentHashMap<>();
```

**優點**：
- 存取速度快（記憶體內）
- 無需網路呼叫

**缺點**：
- 資料重複儲存
- 需要智慧路由來避免重複

**適用場景**：
- 小型資料集（如貨幣轉換表）
- 需要智慧路由的大型資料集（如使用者設定檔）

#### 2. 共享快取 (Shared Cache)
```java
// 使用外部快取服務
RedisCache sharedCache = new RedisCache("redis-cluster");
```

**優點**：
- 無需智慧路由
- 無資料重複
- 容易擴展

**缺點**：
- 需要網路呼叫
- 增加額外延遲

**適用場景**：
- 大型資料集
- 需要水平擴展的系統

## 4. 快取效能衡量

### 快取命中率 (Cache Hit Ratio)
```
快取命中率 = (快取命中次數) / (總請求次數)
```

### 理想快取資料特性
1. **唯讀資料**：不經常變更
2. **頻繁存取**：經常被讀取
3. **資料大小**：偏好快取小型物件

### 快取策略選擇
```java
// 快取決策流程
if (資料是唯讀 && 頻繁存取 && 體積小) {
    // 優先快取
    cache.put(key, data);
} else if (是熱門商品資料) {
    // 快取熱門資料
    cache.put(key, data);
} else {
    // 不適合快取
    // 直接從資料庫讀取
}
```

## 5. 快取失效策略

### 1. 主動更新/刪除
```java
// 更新資料庫時同步更新快取
void updateProduct(Product product) {
    database.update(product);
    cache.update(product.getId(), product);  // 更新快取
    // 或 cache.delete(product.getId());     // 刪除快取
}
```

**優點**：
- 不一致時間窗口極小
- 資料即時性高

**缺點**：
- 僅適用於系統控制的快取
- 增加寫入操作的複雜度

### 2. TTL (Time To Live) 過期策略
```java
// 設定資料存活時間
cache.put(key, data, Duration.ofMinutes(30));
```

**優點**：
- 適用於公有快取
- 實現簡單

**缺點**：
- TTL 值難以精確設定
- 可能導致資料不一致或效能浪費

### TTL 值權衡
- **TTL 過高**：可能服務過期資料
- **TTL 過低**：快取命中率下降，增加後端負載

## 6. 快取設計考量

### 快取空間限制
- 記憶體成本高，無法快取所有資料
- 需要選擇性快取重要且頻繁存取的資料

### 資料選擇策略
1. **存取頻率**：優先快取熱門資料
2. **資料大小**：優先快取小型物件
3. **更新頻率**：優先快取更新頻率低的資料
4. **業務重要性**：優先快取關鍵業務資料

### 快取失效模式
```java
// 組合策略範例
public class CacheStrategy {
    // TTL + 主動失效
    public void updateWithInvalidation(String key, Object data) {
        cache.put(key, data, TTL_30_MINUTES);
        // 同時註冊到失效監聽器
        registerForInvalidation(key);
    }
}
```

## 7. 效能主題總結

### 效能問題識別
- **請求隊列堆積**：識別效能瓶頸點
- **資源飽和度**：監控 CPU、記憶體、磁碟、網路使用率
- **尾部延遲**：關注長尾效應，預防未來問題

### 延遲優化重點
1. **資源利用優化**：
   - CPU、網路、記憶體、磁碟效率提升
   - 序列請求延遲優化

2. **快取策略**：
   - 頻繁讀取、罕見修改的資料應從快取讀取
   - 大幅提升效能

### 併發優化重點
1. **減少序列化**：
   - 鎖粒度優化（鎖條帶化、鎖拆分）
   - 比較並交換 (CAS) 機制

2. **鎖策略選擇**：
   - 低競爭：樂觀鎖定
   - 高競爭：悲觀鎖定
   - 避免死鎖

3. **執行緒與連線池**：
   - 適當設定池大小
   - 避免資源競爭

## 關鍵要點總結

### 快取設計原則
1. **分層快取**：從瀏覽器到資料庫多層次快取
2. **適當策略**：根據資料特性選擇專屬或共享快取
3. **失效管理**：平衡資料即時性與效能
4. **容量規劃**：根據業務需求選擇快取資料

### 效能優化層級
1. **單一請求**：優化資源使用和演算法
2. **併發請求**：減少鎖競爭，提高併發度
3. **系統層級**：適當的快取和資源配置

透過系統性的快取策略，可以顯著提升系統效能，減少後端負載，提供更好的使用者體驗。

